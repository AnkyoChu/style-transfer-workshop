{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import utils\n",
    "from vgg.imagenet_classes import class_names\n",
    "from vgg.VGG import generate_VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version : 1.1.0\n",
      "Devices : [('/cpu:0', 'CPU')]\n"
     ]
    }
   ],
   "source": [
    "print(\"TensorFlow version : {}\".format(tf.__version__))\n",
    "print(\"Devices : {}\".format(utils.get_tensorflow_devices()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# Constants for the image input and output.\n",
    "###############################################################################\n",
    "\n",
    "\n",
    "LOGS = 'logs/4.0'\n",
    "# Output folder for the images.\n",
    "OUTPUT_DIR = 'output/'\n",
    "# Style image to use.\n",
    "STYLE_IMAGE = 'images/udnie.jpg'\n",
    "# Content image to use.\n",
    "CONTENT_IMAGE = 'images/hongkong.jpg'\n",
    "# Image dimensions constants. \n",
    "\n",
    "IMG_W = 256\n",
    "IMG_H = 256\n",
    "CHANNELS = 3\n",
    "\n",
    "MODEL_WEIGHTS = 'vgg/vgg16.npy'\n",
    "\n",
    "DATA_DIR_CONTENT = 'COCO/train2014/'\n",
    "DATA_DIR_STYLE = 'COCO/train2014/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "if tf.gfile.Exists(LOGS):\n",
    "    tf.gfile.DeleteRecursively(LOGS)\n",
    "tf.gfile.MakeDirs(LOGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Constant to put more emphasis on content loss.\n",
    "BETA = 1\n",
    "# Constant to put more emphasis on style loss.\n",
    "ALPHA = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "sess = tf.InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('style_batch'):\n",
    "    style_batch = tf.placeholder(tf.float32,\n",
    "                                  shape=(BATCH_SIZE, IMG_W, IMG_H, CHANNELS),\n",
    "                                  name='style_batch')\n",
    "    \n",
    "with tf.name_scope('content_batch'):\n",
    "    content_batch = tf.placeholder(tf.float32,\n",
    "                                  shape=(BATCH_SIZE, IMG_W, IMG_H, CHANNELS),\n",
    "                                  name='content_batch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from vgg.VGG import generate_VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"style_encoder_VGG\"):\n",
    "    style_encoder_VGG, vgg_scope = generate_VGG16(weights_file=MODEL_WEIGHTS,\n",
    "                                                  apply_preprocess=True,\n",
    "                                                  remove_top=True,\n",
    "                                                  input_tensor=style_batch)\n",
    "    \n",
    "with tf.name_scope(\"content_encoder_VGG\"):\n",
    "    content_encoder_VGG, _ = generate_VGG16(weights_file=MODEL_WEIGHTS,\n",
    "                                                  scope=vgg_scope,\n",
    "                                                  apply_preprocess=True,\n",
    "                                                  remove_top=True,\n",
    "                                                  input_tensor=content_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"Adaptive_IN\"):\n",
    "    eps = 1e-6\n",
    "    \n",
    "    encoded_style = style_encoder_VGG['conv4_1']\n",
    "    encoded_content = content_encoder_VGG['conv4_1']\n",
    "    \n",
    "    mean_c, var_c = tf.nn.moments(encoded_content, [1,2], keep_dims=True)\n",
    "    mean_s, var_s = tf.nn.moments(encoded_style, [1,2], keep_dims=True)\n",
    "    \n",
    "    target = tf.sqrt(var_s)*(encoded_content - mean_c)/(tf.sqrt(var_c) + eps) + mean_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded_content.shape :  (4, 32, 32, 512)\n",
      "encoded_style.shape :  (4, 32, 32, 512)\n",
      "mean_c.shape :  (4, 1, 1, 512)\n",
      "var_c.shape:  (4, 1, 1, 512)\n",
      "mean_s.shape :  (4, 1, 1, 512)\n",
      "var_s.shape:  (4, 1, 1, 512)\n",
      "target.shape :  (4, 32, 32, 512)\n"
     ]
    }
   ],
   "source": [
    "print(\"encoded_content.shape : \", encoded_content.shape)\n",
    "print(\"encoded_style.shape : \", encoded_style.shape)\n",
    "\n",
    "print(\"mean_c.shape : \", mean_c.shape)\n",
    "print(\"var_c.shape: \", var_c.shape)\n",
    "\n",
    "print(\"mean_s.shape : \", mean_s.shape)\n",
    "print(\"var_s.shape: \", var_s.shape)\n",
    "\n",
    "print(\"target.shape : \", target.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Moments for Batch Normalization\n",
    "\n",
    "```python\n",
    "mean, var = tf.nn.moments(encoded_content, [0,1,2], keep_dims=True)\n",
    "print(\"mean.shape : \", mean.shape)\n",
    "print(\"var.shape: \", var.shape)\n",
    "```\n",
    "```\n",
    "mean.shape :  (1, 1, 1, 512)\n",
    "var.shape:  (1, 1, 1, 512)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def _conv_block(prev_layer,kernel_size, nb_fmaps, stride, layer_name, relu=True):\n",
    "    with tf.name_scope(layer_name):\n",
    "        input_fmaps = prev_layer.get_shape().as_list()[-1]\n",
    "        w = tf.Variable(tf.truncated_normal([kernel_size, kernel_size, input_fmaps, nb_fmaps],\n",
    "                                            stddev=0.1), name='W')\n",
    "        b = tf.Variable(tf.constant(1.0, shape=[nb_fmaps]), name='b')\n",
    "        conv = tf.nn.conv2d(prev_layer, w, [1, stride, stride, 1], padding='SAME')\n",
    "        if relu:\n",
    "            return tf.nn.relu(tf.nn.bias_add(conv, b), name=layer_name)\n",
    "        else:\n",
    "            return tf.nn.bias_add(conv, b, name=layer_name)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Up Sampling in TensorFlow : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def _up_sampling(prev_layer, up_factor, layer_name):\n",
    "    with tf.name_scope(layer_name):\n",
    "        b,h,w,c = prev_layer.get_shape().as_list()\n",
    "        return tf.image.resize_nearest_neighbor(prev_layer,[int(w*up_factor), int(h*up_factor)],name=layer_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Example** :\n",
    "\n",
    "```python\n",
    "x = tf.Variable(tf.truncated_normal([16, 8, 8, 56], stddev=2.0)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "x_np = sess.run(x)\n",
    "print(x_np.shape)\n",
    "# output : (16, 8, 8, 56)\n",
    "\n",
    "\n",
    "up_x = _up_sampling(x, 2, 'test_up')\n",
    "up_x_np = sess.run(up_x)\n",
    "print(up_x_np.shape)\n",
    "# output : (16, 16, 16, 56)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('decoder'):\n",
    "    decoder = {}\n",
    "    decoder['conv_block1_1'] = _conv_block(target, 3, 256 , 1, 'conv_block1_1')\n",
    "    decoder['up_sampling1'] = _up_sampling(decoder['conv_block1_1'], 2, 'up_sampling1')\n",
    "    \n",
    "    decoder['conv_block2_1'] = _conv_block(decoder['up_sampling1'], 3, 256 , 1, 'conv_block2_1')\n",
    "    decoder['conv_block2_2'] = _conv_block(decoder['conv_block2_1'], 3, 256 , 1, 'conv_block2_2')\n",
    "    decoder['conv_block2_3'] = _conv_block(decoder['conv_block2_2'], 3, 128 , 1, 'conv_block2_3')\n",
    "    decoder['up_sampling2'] = _up_sampling(decoder['conv_block2_3'], 2, 'up_sampling2')\n",
    "    \n",
    "    decoder['conv_block3_1'] = _conv_block(decoder['up_sampling2'], 3, 128 , 1, 'conv_block3_1')\n",
    "    decoder['conv_block3_2'] = _conv_block(decoder['conv_block3_1'], 3, 64 , 1, 'conv_block3_2')\n",
    "    decoder['up_sampling3'] = _up_sampling(decoder['conv_block3_2'], 2, 'up_sampling3')\n",
    "    \n",
    "    decoder['conv_block4_1'] = _conv_block(decoder['up_sampling3'], 3, 64 , 1, 'conv_block3_1')\n",
    "    decoder['conv_block4_2'] = _conv_block(decoder['conv_block4_1'], 3, 64 , 1, 'conv_block4_2')\n",
    "\n",
    "    decoder['final_conv'] = _conv_block(decoder['conv_block4_1'], 9, 3, 1, 'final_conv', relu=False)\n",
    "    decoder['output'] = tf.multiply(tf.tanh(decoder['final_conv']/255.0), 255, name=\"output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"VGG_content_loss\"):\n",
    "    vgg_content_loss, _ = generate_VGG16(weights_file=MODEL_WEIGHTS,\n",
    "                                        scope=vgg_scope,\n",
    "                                        apply_preprocess=True,\n",
    "                                        remove_top=True,\n",
    "                                        input_tensor=decoder['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('content_loss'):\n",
    "    content_loss = tf.reduce_mean(tf.pow(vgg_content_loss['conv4_1'] - target, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"VGG_style_loss\"):\n",
    "    vgg_style_loss, _ = generate_VGG16(weights_file=MODEL_WEIGHTS,\n",
    "                                        scope=vgg_scope,\n",
    "                                        apply_preprocess=True,\n",
    "                                        remove_top=True,\n",
    "                                        input_tensor=decoder['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "STYLE_LAYERS = [\n",
    "    ('conv1_2', 1.0),\n",
    "    ('conv2_2', 1.0),\n",
    "    ('conv3_3', 1.0),\n",
    "    ('conv4_3', 1.0)\n",
    "]\n",
    "\n",
    "def _gram_matrix_tf(F, B, N, M):\n",
    "    F = tf.reshape(F, (B, M, N))\n",
    "    return ( 1 / M) * tf.matmul(tf.transpose(F, perm=[0,2,1]), F)\n",
    "\n",
    "with tf.name_scope(\"style_loss\"):\n",
    "    style_loss = 0 \n",
    "    for layer_name, weight in STYLE_LAYERS:\n",
    "        \n",
    "        shape = vgg_style_loss[layer_name].get_shape().as_list()\n",
    "        B = shape[0] # batch_size\n",
    "        N = shape[3] # number of feature maps\n",
    "        M = shape[1] * shape[2] # number of features per feature map\n",
    "\n",
    "        G_style = _gram_matrix_tf(style_encoder_VGG[layer_name], B, N, M) # works on Numpy array\n",
    "        G = _gram_matrix_tf(vgg_style_loss[layer_name],B, N, M) # works on Tensor \n",
    "        \n",
    "        style_loss += weight * tf.reduce_mean(tf.pow(G - G_style, 2))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('total_loss'):\n",
    "    total_loss = BETA * content_loss + ALPHA * style_loss\n",
    "    tf.summary.scalar('total_loss', total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "merged = tf.summary.merge_all()\n",
    "writer = tf.summary.FileWriter(LOGS, sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('train'):\n",
    "    optimizer = tf.train.AdamOptimizer(0.02)\n",
    "    train_step = optimizer.minimize(total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "style_generator = ImageDataGenerator(rotation_range=20,\n",
    "                                     width_shift_range=0.2,\n",
    "                                     height_shift_range=0.2,\n",
    "                                     vertical_flip=True).flow_from_directory(DATA_DIR_STYLE,\n",
    "                                                         target_size=(IMG_W, IMG_H),\n",
    "                                                         batch_size=BATCH_SIZE,\n",
    "                                                         class_mode=None)\n",
    "\n",
    "\n",
    "content_generator = ImageDataGenerator(rotation_range=20,\n",
    "                                     width_shift_range=0.2,\n",
    "                                     height_shift_range=0.2,\n",
    "                                     vertical_flip=True).flow_from_directory(DATA_DIR_CONTENT,\n",
    "                                                         target_size=(IMG_W, IMG_H),\n",
    "                                                         batch_size=BATCH_SIZE,\n",
    "                                                         class_mode=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "ITERATIONS = 2000\n",
    "\n",
    "for it in range(ITERATIONS):\n",
    "    content = content_generator.next()\n",
    "    style = style_generator.next()\n",
    "    \n",
    "    feed={}\n",
    "    feed[content_batch] = content\n",
    "    feed[style_batch] = style\n",
    "    \n",
    "    if it%50 == 49 : \n",
    "        run_options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)\n",
    "        run_metadata = tf.RunMetadata()\n",
    "        \n",
    "        summary, _ = sess.run([merged, train_step],\n",
    "                              feed_dict=feed,\n",
    "                              options=run_options,\n",
    "                              run_metadata=run_metadata)\n",
    "            \n",
    "        writer.add_summary(summary, it)\n",
    "        writer.add_run_metadata(run_metadata, 'step%03d' % i)\n",
    "            \n",
    "    else :\n",
    "        summary, _ = sess.run([merged, train_step], feed_dict=feed)\n",
    "        writer.add_summary(summary, it)\n",
    "\n",
    "    if it%500 == 0:\n",
    "        \n",
    "        feed={}\n",
    "        feed[content_batch] = [content_image[0]]*BATCH_SIZE\n",
    "        feed[style_batch] = [style_image[0]]*BATCH_SIZE\n",
    "        \n",
    "        _image = sess.run(decoder['output'], feed_dict=feed)\n",
    "        print('Iteration %d' % (it))\n",
    "        filename = 'output/stylized_feedforward_IN_iter{}.png'.format(it)\n",
    "        utils.save_image(filename, _image)\n",
    "    elif it%50 == 0:\n",
    "        print(\"--> {} / {}\".format(it, ITERATIONS))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

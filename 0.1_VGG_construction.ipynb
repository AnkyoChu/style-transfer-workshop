{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from scipy.misc import imread, imresize\n",
    "\n",
    "# class names for ImaneNet dataset\n",
    "from imagenet_classes import class_names\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dir for tensorboard file (for graph visualization)\n",
    "logs_path = 'tmp/logs'\n",
    "\n",
    "if tf.gfile.Exists(logs_path):\n",
    "    tf.gfile.DeleteRecursively(logs_path)\n",
    "tf.gfile.MakeDirs(logs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# information about image size\n",
    "IMG_W = 224\n",
    "IMG_H = 224\n",
    "CHANNELS = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load weights (numpy arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "VGG19_weights_file = \"vgg19.npy\"\n",
    "VGG19_weights = np.load(VGG19_weights_file, encoding='latin1').item()\n",
    "print(type(VGG19_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logs_path = 'tmp/logs'\n",
    "\n",
    "if tf.gfile.Exists(logs_path):\n",
    "    tf.gfile.DeleteRecursively(logs_path)\n",
    "tf.gfile.MakeDirs(logs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IMG_W = 224\n",
    "IMG_H = 224\n",
    "CHANNELS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['conv3_3', 'fc6', 'conv3_1', 'conv4_3', 'conv5_4', 'conv5_2', 'conv1_2', 'conv4_1', 'conv3_4', 'conv2_1', 'fc7', 'conv2_2', 'conv4_2', 'conv3_2', 'fc8', 'conv1_1', 'conv5_1', 'conv4_4', 'conv5_3'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VGG19_weights.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3, 512, 512)\n",
      "(512,)\n"
     ]
    }
   ],
   "source": [
    "print(VGG19_weights['conv5_1'][0].shape)\n",
    "print(VGG19_weights['conv5_1'][1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _get_weights(layer_name, weights):\n",
    "    \"\"\"\n",
    "    Load weights with name 'layer_name'\n",
    "    weights[layer_name][0] : weights (conv kernel or matrix)\n",
    "    weights[layer_name][1] : bias vector\n",
    "    \"\"\"\n",
    "    W = weights[layer_name][0]\n",
    "    b = weights[layer_name][1]\n",
    "    return W, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25088, 4096)\n",
      "(4096,)\n"
     ]
    }
   ],
   "source": [
    "W, b = _get_weights('fc6', VGG19_weights)\n",
    "print(W.shape)\n",
    "print(b.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG Construction \n",
    "\n",
    "- store tensors in a python dictionary \n",
    "    - after each \"conv + ReLU\"\n",
    "    - after each \"pooling\" (max pooling)\n",
    "    - after each \"dense layer + ReLU\"\n",
    "    - after softmax layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input : batch of 1 image. \n",
    "# we are using tf.Variable() to perform optimization on this image (see next notebooks)\n",
    "model['input'] = tf.get_variable(\"input\", dtype = 'float32', shape=(1,IMG_W, IMG_H, CHANNELS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing : RGB-> BRG and mean substraction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _preprocess(prev_layer):\n",
    "    \"\"\"\n",
    "    Apply preprocessing step : subtract image mean from ImageNet dataset.\n",
    "    And RGB -> BGR \n",
    "    \"\"\"\n",
    "    # BGR format \n",
    "    VGG_MEAN = [103.939, 116.779, 123.68]\n",
    "    \n",
    "    red, green, blue = tf.split(axis=3, num_or_size_splits=3, value=prev_layer)\n",
    "    bgr = tf.concat(axis=3, values=[blue - VGG_MEAN[0], green - VGG_MEAN[1], red - VGG_MEAN[2],])\n",
    "    return bgr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model[\"preprocess\"] = _preprocess(model['input'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable sharing \n",
    "\n",
    "In more complex models for style transfer we will use many VGG networks (as encoder, for style and content losses). \n",
    "\n",
    "So we can use `tf.get_variable()` and `tf.variable_scope()` for variable sharing. \n",
    "\n",
    "See TensorFlow tutorial about variable sharing for more information : \n",
    "    - https://www.tensorflow.org/programmers_guide/variable_scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _conv2d_relu(prev_layer, layer_name, weights):\n",
    "    \"\"\"\n",
    "    Return the Conv2D + RELU layer using the weights, biases from the VGG\n",
    "    model at 'layer_name'.\n",
    "    \"\"\"\n",
    "    W_np, b_np = _get_weights(layer_name, weights)\n",
    "    \n",
    "    with tf.variable_scope(layer_name):\n",
    "        \n",
    "        W = tf.get_variable('W', shape=tuple(W_np.shape),\n",
    "                            dtype=W_np.dtype, trainable=False,\n",
    "                            initializer=tf.constant_initializer(W_np))\n",
    "        \n",
    "        b = tf.get_variable('b', shape=tuple(b_np.shape),\n",
    "                            dtype=b_np.dtype, trainable=False,\n",
    "                            initializer=tf.constant_initializer(b_np))\n",
    "        \n",
    "        conv = tf.nn.conv2d(prev_layer, filter=W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "        out = tf.nn.bias_add(conv, b)\n",
    "        acti =  tf.nn.relu(out, name=layer_name)\n",
    "        return acti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _pool(prev_layer, layer_name):\n",
    "    \"\"\"\n",
    "    Return the MaxPooling layer.\n",
    "    \"\"\"\n",
    "    with tf.name_scope(layer_name):\n",
    "        return tf.nn.max_pool(prev_layer, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model['conv1_1']  = _conv2d_relu(model['preprocess'], 'conv1_1', VGG19_weights)\n",
    "model['conv1_2']  = _conv2d_relu(model['conv1_1'], 'conv1_2', VGG19_weights)\n",
    "model['pool_1'] = _pool(model['conv1_2'], 'pool_1')\n",
    "\n",
    "model['conv2_1']  = _conv2d_relu(model['pool_1'], 'conv2_1', VGG19_weights)\n",
    "model['conv2_2']  = _conv2d_relu(model['conv2_1'], 'conv2_2', VGG19_weights)\n",
    "model['pool_2'] = _pool(model['conv2_2'], 'pool_2')\n",
    "\n",
    "model['conv3_1']  = _conv2d_relu(model['pool_2'], 'conv3_1', VGG19_weights)\n",
    "model['conv3_2']  = _conv2d_relu(model['conv3_1'], 'conv3_2', VGG19_weights)\n",
    "model['conv3_3']  = _conv2d_relu(model['conv3_2'], 'conv3_3', VGG19_weights)\n",
    "model['conv3_4']  = _conv2d_relu(model['conv3_3'], 'conv3_4', VGG19_weights)\n",
    "model['pool_3'] = _pool(model['conv3_4'], 'pool_3')\n",
    "\n",
    "model['conv4_1']  = _conv2d_relu(model['pool_3'], 'conv4_1', VGG19_weights)\n",
    "model['conv4_2']  = _conv2d_relu(model['conv4_1'], 'conv4_2', VGG19_weights)\n",
    "model['conv4_3']  = _conv2d_relu(model['conv4_2'], 'conv4_3', VGG19_weights)\n",
    "model['conv4_4']  = _conv2d_relu(model['conv4_3'], 'conv4_4', VGG19_weights)\n",
    "model['pool_4'] = _pool(model['conv4_4'], 'pool_4')\n",
    "\n",
    "model['conv5_1']  = _conv2d_relu(model['pool_4'], 'conv5_1', VGG19_weights)\n",
    "model['conv5_2']  = _conv2d_relu(model['conv5_1'], 'conv5_2', VGG19_weights)\n",
    "model['conv5_3']  = _conv2d_relu(model['conv5_2'], 'conv5_3', VGG19_weights)\n",
    "model['conv5_4']  = _conv2d_relu(model['conv5_3'], 'conv5_4', VGG19_weights)\n",
    "model['pool_5'] = _pool(model['conv5_4'], 'pool_5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _flatten(prev_layer):\n",
    "    \"\"\"\n",
    "    Reshape layer, flatten operation.\n",
    "    \"\"\"\n",
    "    \n",
    "    with tf.name_scope('flatten'):\n",
    "        shape = int(np.prod(prev_layer.get_shape()[1:]))\n",
    "        return tf.reshape(prev_layer, [-1, shape])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model['flatten'] = _flatten(model['pool_5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _fc_relu(prev_layer, layer_name, weights):\n",
    "    \"\"\"\n",
    "    Return the Dense/Fully Connected  + ReLU layer using the weights, biases from the VGG model\n",
    "    \"\"\"\n",
    "    W_np, b_np = _get_weights(layer_name, weights)\n",
    "    with tf.variable_scope(layer_name):\n",
    "        W = tf.get_variable('W', shape=tuple(W_np.shape),\n",
    "                            dtype=W_np.dtype, trainable=False,\n",
    "                            initializer=tf.constant_initializer(W_np))\n",
    "        \n",
    "        b = tf.get_variable('b', shape=tuple(b_np.shape),\n",
    "                            dtype=b_np.dtype, trainable=False,\n",
    "                            initializer=tf.constant_initializer(b_np))\n",
    "        \n",
    "        return tf.nn.relu(tf.nn.bias_add(tf.matmul(prev_layer, W), b))\n",
    "\n",
    "def _fc_linear(prev_layer, layer_name, weights):\n",
    "        \n",
    "    W_np, b_np = _get_weights(layer_name, weights)\n",
    "    with tf.variable_scope(layer_name):\n",
    "        W = tf.get_variable('W', shape=tuple(W_np.shape),\n",
    "                            dtype=W_np.dtype, trainable=False,\n",
    "                            initializer=tf.constant_initializer(W_np))\n",
    "        \n",
    "        b = tf.get_variable('b', shape=tuple(b_np.shape),\n",
    "                            dtype=b_np.dtype, trainable=False,\n",
    "                            initializer=tf.constant_initializer(b_np))\n",
    "        \n",
    "        return tf.nn.bias_add(tf.matmul(prev_layer, W), b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model['fc6'] = _fc_relu(model['flatten'], 'fc6', VGG19_weights)\n",
    "model['fc7'] = _fc_relu(model['fc6'], 'fc7', VGG19_weights)\n",
    "model['fc8'] = _fc_linear(model['fc7'], 'fc8', VGG19_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _prob(prev_layer, layer_name):\n",
    "    \"\"\"\n",
    "    Returns the softmax.\n",
    "    \"\"\"\n",
    "    with tf.name_scope(layer_name):\n",
    "        return tf.nn.softmax(prev_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model['prob'] = _prob(model['fc8'], 'prob')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# variable initialization : assign trained values (conv kernels, matrices ans biases vectors) to the graph\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add the graph to TensorBoard visualization\n",
    "writer = tf.summary.FileWriter(logs_path, sess.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img1 = imread('../images/golden_retriever.jpg')\n",
    "img1 = imresize(img1, (IMG_W, IMG_H))\n",
    "img1 = img1.reshape((1, IMG_W, IMG_H, CHANNELS))\n",
    "print(img1.dtype)\n",
    "plt.imshow(img1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# assign to the input the image \n",
    "_ = sess.run(model['input'].assign(img1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prob = sess.run(model['prob'])[0]\n",
    "preds = (np.argsort(prob)[::-1])[0:5]\n",
    "for p in preds:\n",
    "    print(class_names[p], prob[p])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"VGG\") as vgg_scope :\n",
    "    W = tf.get_variable('W',shape=(200,200))\n",
    "    print(type(vgg_scope))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(isinstance(vgg_scope, tf.VariableScope))\n",
    "print(isinstance(vgg_scope, str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope(vgg_scope, reuse=True):\n",
    "    W1 = tf.get_variable(\"W\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert W is W1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"input1\"):\n",
    "    input1 = tf.Variable([[10,8],[8,4]], dtype='float32', name='input')\n",
    "\n",
    "with tf.name_scope(\"input2\"):\n",
    "    input2 = tf.Variable([[4,4],[4,4]], dtype='float32',name='input')\n",
    "\n",
    "with tf.name_scope(\"VGG1\"): \n",
    "    with tf.variable_scope(\"foo\") as foo_scope:\n",
    "        B = tf.get_variable(\"B\",shape=(2,2), initializer=tf.constant_initializer(0.5))\n",
    "        print(B.name)\n",
    "        print(foo_scope.name)\n",
    "        out1 = tf.matmul(a=input1, b=B, name='out1')\n",
    "        \n",
    "with tf.name_scope(\"VGG2\"):\n",
    "    with tf.variable_scope(foo_scope, reuse=True):\n",
    "        B1 = tf.get_variable(\"B\")\n",
    "        print(B1.name)\n",
    "        out2 = tf.matmul(a=input2, b=B1, name='out2')\n",
    "\n",
    "assert B1 is B\n",
    "\n",
    "with tf.name_scope(\"merge\"): \n",
    "    final_out = tf.matmul(a=out1, b=out2, name='out')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "writer = tf.summary.FileWriter(logs_path, sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}